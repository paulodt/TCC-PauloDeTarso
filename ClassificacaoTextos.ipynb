{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do TCC de Paulo de Tarso, da EMAp FGV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#Se for preciso, executar o comando abaixo\n",
    "#nltk.download()\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "\n",
    "#Ignorar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos auxiliares\n",
    "### Código para remover símbolos das strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    s = s.replace(\"\\n\",\" \")\n",
    "    return ''.join(x for x in unicodedata.normalize('NFKD', s)\n",
    "                   if x in string.ascii_letters + \" \").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parâmetros\n",
    "inicio_atas = 104 #Utilizarei as atas a partir de 2005\n",
    "final_atas = 206\n",
    "\n",
    "total_atas = final_atas - inicio_atas + 1\n",
    "atas = range(inicio_atas,final_atas+1)\n",
    "\n",
    "path = \"D:/Users/paulotarsosantos/Documents/Documentos/TCC/Atas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização dos textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter textos dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "#Ir para a pasta com os arquivos\n",
    "os.chdir(path)\n",
    "\n",
    "#Obter o texto dos arquivos\n",
    "for n in atas:\n",
    "    file = open(\"COPOM_\" + str(n) + \".txt\")\n",
    "    texts.append(clean_string(file.read()))\n",
    "    file.close()\n",
    "\n",
    "#Voltar uma pasta\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetorizar os textos obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sw = [clean_string(word) for word in \n",
    "             open(\"stopwords.txt\",encoding=\"utf-8\").read().splitlines()[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário:\n",
      "\n",
      "['copom', 'meta', 'pais']\n",
      "\n",
      "Vetores de cada texto:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'copom acredita no aceleramento da economia do pais e reduz a meta em  bps': '[1 1 1]',\n",
       " 'copom decide cortar a meta da selic em  bps': '[1 1 0]',\n",
       " 'copom defende que uma taxa de juros menor incentiva o investimento no pais': '[1 0 1]'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemplo\n",
    "textos = [\"COPOM decide cortar a meta da Selic em 100 bps.\",\n",
    "         \"COPOM acredita no aceleramento da economia do país e reduz a meta em 200 bps.\",\n",
    "         \"COPOM defende que uma taxa de juros menor incentiva o investimento no país.\"]\n",
    "textos = [clean_string(texto) for texto in textos]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "\n",
    "vetorizador = CV(stop_words=sw,min_df=2)\n",
    "vetores = vetorizador.fit_transform(textos).toarray()\n",
    "\n",
    "print(\"Vocabulário:\\n\")\n",
    "print(vetorizador.get_feature_names())\n",
    "\n",
    "print(\"\\nVetores de cada texto:\")\n",
    "dict(zip(textos,[str(elt) for elt in vetores]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CV(stop_words=sw,min_df=10)\n",
    "arrays = vectorizer.fit_transform(texts).toarray()\n",
    "#d_arrays = dict(zip(range(inicio_atas,final_atas+1),arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter os valores das variações na meta da Selic em cada reunião do Copom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"Cortes.txt\")\n",
    "cortes = [int(line.split(\";\")[2]) for line in file.read().splitlines()[1:]]\n",
    "cortes = [int(n/abs(n)) if n != 0 else 0 for n in cortes]\n",
    "cortes.reverse()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de classificação\n",
    "Me basearei nos modelos contidos na biblioteca Scikit Learn. Os modelos estão em http://scikit-learn.org/stable/supervised_learning.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que recebe o modelo desejado e retorna o score médio e o valor predito médio para a última reunião (não presente na amostra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RunModel(model,n_executions,next_copom = False):\n",
    "    counter = n_executions\n",
    "    classifier = model\n",
    "    score = 0\n",
    "    last_prediction = 0\n",
    "    for i in range(n_executions):\n",
    "        try:        \n",
    "            #Separação em dados para treino e dados para teste do modelo\n",
    "            #(Aqui, utilizo até a antepenúltima reunião; a penúltima será\n",
    "            #utilizada para prever o resultado da última).\n",
    "            X_train,X_test,y_train,y_test = tts(arrays[:-2],cortes[:-1],train_size=0.9)\n",
    "\n",
    "            #Treino do modelo nos dados\n",
    "            classifier.fit(X_train,y_train)\n",
    "\n",
    "            #Resultados\n",
    "            score += classifier.score(X_test,y_test)\n",
    "            if not next_copom:\n",
    "                last_prediction += classifier.predict(arrays[-2])[0]\n",
    "            else:\n",
    "                last_prediction += classifier.predict(arrays[-1])[0]\n",
    "        except:\n",
    "            counter -= 1\n",
    "        \n",
    "    score /= counter\n",
    "    last_prediction /= counter\n",
    "    \n",
    "    return [score,last_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier as SGDC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier as GPC\n",
    "from sklearn.cross_decomposition import PLSRegression as PLSR\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "from sklearn.naive_bayes import BernoulliNB as BNB\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import BaggingClassifier as BC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "from sklearn.ensemble import VotingClassifier as VC\n",
    "\n",
    "models = [LR(),LDA(),QDA(),KRR(),SVC(),SGDC(),KNC(),GPC(),PLSR(),\n",
    "          GNB(),MNB(),BNB(),DTC(),BC(),RFC(),ETC(),ABC(),GBC(),MLPC(),\n",
    "          VC(estimators=[('LDA', LDA()), ('ETC', ETC()),\n",
    "                        ('GBC', GBC())], voting='hard')]\n",
    "\n",
    "names = [\"Generalized Linear Model\",\"Linear Discriminant Analysis\",\n",
    "        \"Quadratic Discriminant Analysis\",\"Kernel Ridge Regression\",\n",
    "        \"Support Vector Machine Classifier\",\"Stochastic Gradient Descent\",\n",
    "        \"K Nearest Neighbors\",\"Gaussian Process\",\n",
    "         \"Partial Least Squares Regressors\",\"Gaussian Naive Bayes\",\n",
    "         \"Multinomial Naive Bayes\",\"Bernoulli Naive Bayes\",\n",
    "         \"Decision Tree Classifier\",\"Bagging meta-estimator\",\n",
    "        \"Random Forest Classifier\",\"Extremely Randomized Trees\",\n",
    "        \"AdaBoost Classifier\",\"Gradient Tree Boosting\",\n",
    "        \"Multi-layer Perceptron Classifier\",\"Voting Classifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    \n",
    "    results.append(RunModel(models[i],100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenar e mostrar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [result[0] for result in results]\n",
    "last_predictions = [result[1] for result in results]\n",
    "\n",
    "model_results = list(zip(names,scores,last_predictions))\n",
    "\n",
    "model_results.sort(key=lambda x:x[1])\n",
    "model_results.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Voting Classifier', 0.75454545454545441, -0.91000000000000003),\n",
       " ('Linear Discriminant Analysis', 0.73999999999999955, -0.69999999999999996),\n",
       " ('Extremely Randomized Trees', 0.73090909090909084, -0.94999999999999996),\n",
       " ('Gradient Tree Boosting', 0.69636363636363607, -0.77000000000000002),\n",
       " ('Gaussian Naive Bayes', 0.68181818181818177, 0.0),\n",
       " ('Bagging meta-estimator', 0.67909090909090875, -0.81000000000000005),\n",
       " ('Random Forest Classifier', 0.66909090909090896, -0.93000000000000005),\n",
       " ('Decision Tree Classifier', 0.66272727272727283, -0.5),\n",
       " ('Kernel Ridge Regression', 0.60476794064129424, -0.80932512970619075),\n",
       " ('AdaBoost Classifier', 0.58454545454545437, -0.56000000000000005),\n",
       " ('Stochastic Gradient Descent', 0.56727272727272704, -0.90000000000000002),\n",
       " ('Generalized Linear Model', 0.56341630791835073, -0.79791251233093607),\n",
       " ('Multinomial Naive Bayes', 0.5536363636363637, -0.01),\n",
       " ('Bernoulli Naive Bayes', 0.47181818181818158, -0.40000000000000002),\n",
       " ('Multi-layer Perceptron Classifier',\n",
       "  0.45000000000000012,\n",
       "  -0.60999999999999999),\n",
       " ('K Nearest Neighbors', 0.42909090909090947, -1.0),\n",
       " ('Support Vector Machine Classifier', 0.4163636363636366, -1.0),\n",
       " ('Quadratic Discriminant Analysis',\n",
       "  0.37090909090909102,\n",
       "  -0.47999999999999998),\n",
       " ('Gaussian Process', 0.3027272727272729, 1.0),\n",
       " ('Partial Least Squares Regressors',\n",
       "  0.14523738826364896,\n",
       "  array([-1.62277535]))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"Results.csv\",\"w\")\n",
    "[file.write(names[i] + \";\" + str(scores[i]) + \";\" +\n",
    "            str(last_predictions[i]) + \"\\n\") for i in range(len(scores))]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2503604459268276, -52.179634749641636]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "RunModel(LR(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8111999999999947, -3.6000000000000001]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "RunModel(LDA(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38063636363636399, -0.48499999999999999]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "RunModel(QDA(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-671c6a148cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_ridge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKernelRidge\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mKRR\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRunModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'KR' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "RunModel(KRR(),10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.86399999999999966, 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "RunModel(SVC(),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier as SGDC\n",
    "RunModel(SGDC(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "RunModel(KNC(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier as GPC\n",
    "RunModel(GPC(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression as PLSR\n",
    "RunModel(PLSR(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "RunModel(GNB(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "RunModel(MNB(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB as BNB\n",
    "RunModel(BNB(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "RunModel(DTC(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier as BC\n",
    "RunModel(BC(),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "RunModel(RFC(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.83418181818182346, -66.900000000000006]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "RunModel(ETC(),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "RunModel(ABC(),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "RunModel(GBC(),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron Classifier\n",
    "Neural Network with backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "RunModel(MLPC(hidden_layer_sizes=(20, 5)),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Voting Classifier\n",
    "Utiliza múltiplos modelos e encontra os pesos para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "RunModel(VC(estimators=[('LDA', LDA()), ('ETC', ETC()),\n",
    "                        ('GBC', GBC())], voting='hard'),10,next_copom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
